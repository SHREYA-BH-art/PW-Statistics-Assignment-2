{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Theoritical Questions**"
      ],
      "metadata": {
        "id": "eYrhnYKnsoyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is hypothesis testing in statistics?\n",
        "* Hypothesis testing in statistics is a method used to make decisions or inferences about population parameters based on sample data. It involves forming two competing statements: the null hypothesis (H‚ÇÄ), which represents no effect or status quo, and the alternative hypothesis (H‚ÇÅ), which represents the effect or change. A test statistic is calculated from the sample and compared to a critical value or used to find a p-value. If the p-value is less than the chosen significance level (often 0.05), H‚ÇÄ is rejected. This process helps determine if observed data is statistically significant.\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "* The null hypothesis (H‚ÇÄ) is a default statement in statistics that assumes no effect, difference, or relationship exists between variables. It represents the status quo or baseline condition. The alternative hypothesis (H‚ÇÅ or Ha), on the other hand, proposes that there is an effect, a difference, or a relationship. Hypothesis testing evaluates evidence against H‚ÇÄ to determine if H‚ÇÅ should be supported. If the data provides strong evidence (usually via a low p-value), H‚ÇÄ is rejected in favor of H‚ÇÅ. Thus, the key difference lies in what each hypothesis claims about the population.\n",
        "3.  What is the significance level in hypothesis testing, and why is it important?\n",
        "* The significance level, denoted by alpha (Œ±), is the threshold used in hypothesis testing to determine whether to reject the null hypothesis. Commonly set at 0.05 (5%), it represents the probability of rejecting the null hypothesis when it is actually true‚Äîa Type I error. The significance level is important because it defines how much risk of error is acceptable in drawing conclusions from data. A smaller Œ± reduces the chance of a false positive but increases the chance of a false negative. It helps ensure reliable and consistent decision-making in statistical analysis.\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "* A p-value in hypothesis testing represents the probability of obtaining results as extreme as, or more extreme than, the observed data, assuming the null hypothesis is true. It measures the strength of evidence against the null hypothesis. A small p-value (typically less than 0.05) indicates strong evidence to reject the null hypothesis, suggesting the observed effect is statistically significant. Conversely, a large p-value suggests insufficient evidence to reject the null. The p-value helps researchers assess whether their findings are likely due to chance or reflect a real effect.\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "* Interpreting the p-value in hypothesis testing involves assessing how compatible the observed data is with the null hypothesis. A low p-value (typically ‚â§ 0.05) suggests that the observed results are unlikely under the null hypothesis, leading to its rejection in favor of the alternative hypothesis. This indicates statistical significance. A high p-value (> 0.05) means the data is consistent with the null hypothesis, so there's not enough evidence to reject it. However, a high p-value doesn't prove the null is true‚Äîit just means there's insufficient evidence against it.\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "* In hypothesis testing, a Type 1 error occurs when the null hypothesis is rejected even though it is true‚Äîa false positive. The probability of making a Type 1 error is the significance level (Œ±), often set at 0.05. A Type 2 error happens when the null hypothesis is not rejected despite being false‚Äîa false negative. The probability of a Type 2 error is denoted by Œ≤, and its complement (1 - Œ≤) is called the power of the test. Both errors impact the reliability of statistical conclusions.\n",
        "7.  What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "* A one-tailed test in hypothesis testing checks for an effect in one specific direction‚Äîeither greater than or less than a certain value. It‚Äôs used when the research hypothesis predicts the direction of the effect. A two-tailed test, on the other hand, checks for an effect in either direction, testing whether a value is significantly different (either higher or lower) than the hypothesized value. It‚Äôs used when no specific direction is predicted. The choice between them affects the p-value calculation and the critical region for rejecting the null hypothesis.\n",
        "8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "* A Z-test is a statistical test used in hypothesis testing to determine whether there is a significant difference between sample and population means (or between two sample means) when the population standard deviation is known and the data follows a normal distribution. It's typically used for large sample sizes (n ‚â• 30). Common applications include testing the mean of a single sample or comparing two means. The test calculates a Z-score, which is then compared to critical values from the standard normal distribution to decide whether to reject the null hypothesis.\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "* The Z-score in hypothesis testing is calculated using the formula:\n",
        "\n",
        "ùëç\n",
        "=\n",
        "ùëã\n",
        "Àâ\n",
        "‚àí\n",
        "ùúá\n",
        "ùúé\n",
        "/\n",
        "ùëõ\n",
        "Z=\n",
        "œÉ/\n",
        "n\n",
        "‚Äã\n",
        "\n",
        "X\n",
        "Àâ\n",
        " ‚àíŒº\n",
        "‚Äã\n",
        "\n",
        "Where:\n",
        "\n",
        "ùëã\n",
        "Àâ\n",
        "X\n",
        "Àâ\n",
        "  = sample mean\n",
        "\n",
        "ùúá\n",
        "Œº = population mean (under the null hypothesis)\n",
        "\n",
        "ùúé\n",
        "œÉ = population standard deviation\n",
        "\n",
        "ùëõ\n",
        "n = sample size\n",
        "\n",
        "The Z-score represents how many standard errors the sample mean is from the population mean. It helps determine the probability of observing a result as extreme as the one obtained, assuming the null hypothesis is true. This value is then used to find the p-value.\n",
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "* The t-distribution is a probability distribution used in hypothesis testing when the sample size is small (typically n < 30) and the population standard deviation is unknown. It‚Äôs similar to the normal distribution but has heavier tails, meaning it accounts for more variability in smaller samples.\n",
        "\n",
        "You should use the t-distribution instead of the normal distribution when:\n",
        "The sample size is small.\n",
        "The population standard deviation (œÉ) is unknown\n",
        "The data is approximately normally distributed\n",
        "As sample size increases, the t-distribution approaches the normal distribution.\n",
        "11.  What is the difference between a Z-test and a T-test?\n",
        "* A Z-test is used when the population variance is known and the sample size is large (typically n > 30). It relies on the normal distribution to test hypotheses about population means. A T-test is used when the population variance is unknown and the sample size is small (n ‚â§ 30). It uses the t-distribution, which accounts for extra uncertainty due to estimating the variance from the sample. In summary, Z-test applies with known variance and large samples; T-test is for unknown variance and smaller samples, making it more flexible in practical scenarios.\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "* The T-test is a statistical method used to determine if there is a significant difference between the means of two groups or between a sample mean and a known value when the population variance is unknown. It uses the t-distribution, which adjusts for small sample sizes and uncertainty in estimating variance. In hypothesis testing, the T-test compares the calculated t-statistic to a critical value from the t-distribution to decide whether to reject the null hypothesis. It‚Äôs commonly used for small samples or when population variance is not known.\n",
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "* The Z-test and T-test are both used in hypothesis testing to compare means, but they differ based on sample size and knowledge of population variance. When the population variance is known and the sample size is large, the Z-test is appropriate, using the normal distribution. When the population variance is unknown and the sample size is small, the T-test is used, relying on the t-distribution, which accounts for extra uncertainty. As sample size increases, the t-distribution approaches the normal distribution, making the T-test results similar to the Z-test for large samples.\n",
        "14. What is a confidence interval, and how is it used to interpret statistical results/\n",
        "* A confidence interval (CI) is a range of values, calculated from sample data, that likely contains the true population parameter (like a mean) with a specified confidence level. It quantifies uncertainty by providing an estimated range instead of a single value. In statistical results, the CI helps interpret precision and reliability: a narrower interval means more precise estimates. If a confidence interval for a difference between groups does not include zero, it suggests a statistically significant effect. It‚Äôs a key tool for understanding and communicating the uncertainty in estimates.\n",
        "15. What is the margin of error, and how does it affect the confidence interval?\n",
        "* The margin of error (MOE) is the maximum expected difference between a sample estimate and the true population parameter. It reflects the uncertainty or potential error in the estimate due to sampling variability. The margin of error directly affects the confidence interval width: a larger MOE results in a wider interval, indicating less precision, while a smaller MOE produces a narrower, more precise interval. MOE depends on the sample size, variability in the data, and the chosen confidence level‚Äîhigher confidence levels increase MOE, widening the interval to be more certain the true value lies within it.\n",
        "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "* Bayes' Theorem in statistics provides a way to update the probability of a hypothesis based on new evidence. It combines prior knowledge (prior probability) with the likelihood of observed data to calculate the updated probability (posterior probability). This is significant because it allows for dynamic learning ‚Äîimproving estimates as more data becomes available. Bayes' Theorem is widely used in fields like machine learning, medical diagnosis, and decision making, enabling more informed and probabilistic reasoning rather than relying on fixed assumptions. It bridges prior beliefs and observed data effectively.\n",
        "17. What is the Chi-square distribution, and when is it used?\n",
        "* The Chi-square distribution is a probability distribution used primarily in hypothesis testing and confidence interval estimation for categorical data. It describes the distribution of a sum of squared independent standard normal variables. It‚Äôs commonly used in Chi-square tests to assess relationships between categorical variables (like in a contingency table) or to test the goodness-of-fit of observed data to an expected distribution. It‚Äôs especially useful for testing independence, homogeneity, and variance estimates in large samples. The distribution is skewed and depends on degrees of freedom, becoming more symmetric as degrees increase.\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "* The Chi-square goodness of fit test assesses whether observed categorical data match an expected distribution. It compares the observed frequencies in each category to the frequencies expected under a specific hypothesis. To apply the test, you:\n",
        "\n",
        "1. State the null hypothesis that observed data fit the expected distribution.\n",
        "2. Calculate the Chi-square statistic: sum of $(\\text{observed} - \\text{expected})^2 / \\text{expected}$ across categories.\n",
        "3. Determine the degrees of freedom (number of categories minus 1).\n",
        "4. Compare the statistic to the critical Chi-square value from tables.\n",
        "   If the statistic exceeds the critical value, reject the null, indicating a poor fit.\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "* The F-distribution is a probability distribution that arises from the ratio of two independent chi-square distributed variables divided by their respective degrees of freedom. It is right-skewed and depends on two sets of degrees of freedom.\n",
        "\n",
        "In hypothesis testing, the F-distribution is mainly used in ANOVA (Analysis of Variance) to compare the variances of two or more groups and determine if their means are significantly different. It‚Äôs also used in regression analysis to test overall model significance and in tests comparing variances of populations (like the F-test).\n",
        "20. What is an ANOVA test, and what are its assumptions?\n",
        "* ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups to see if at least one group mean is significantly different from the others. Instead of multiple t-tests, ANOVA tests all groups simultaneously by analyzing variance within and between groups.\n",
        "\n",
        "**Key assumptions of ANOVA are:**\n",
        "\n",
        "1. **Independence:** Samples are independent.\n",
        "2. **Normality:** Data in each group follow a normal distribution.\n",
        "3. **Homogeneity of variances:** Variances across groups are equal.\n",
        "   Violating these assumptions can affect test validity.\n",
        "21. What are the different types of ANOVA tests?\n",
        "* There are several types of ANOVA tests, mainly differing by the study design and the number of factors involved:\n",
        "\n",
        "1. **One-Way ANOVA**\n",
        "\n",
        "   * Compares means of three or more groups based on a single factor (independent variable).\n",
        "\n",
        "2. **Two-Way ANOVA**\n",
        "\n",
        "   * Examines the effect of two independent factors simultaneously on the dependent variable, including interaction effects.\n",
        "\n",
        "3. **Repeated Measures ANOVA**\n",
        "\n",
        "   * Used when the same subjects are measured multiple times under different conditions or over time.\n",
        "\n",
        "4. **Multivariate ANOVA (MANOVA)**\n",
        "\n",
        "   * Tests multiple dependent variables simultaneously across groups.\n",
        "\n",
        "Each type helps analyze different experimental designs and data structures.\n",
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "* The F-test is a statistical test that compares the variances of two or more groups to determine if they are significantly different. It calculates an F-statistic as the ratio of variance between groups to variance within groups. In hypothesis testing, the F-test helps decide whether group means differ significantly by testing the null hypothesis that all group means are equal. A large F-statistic suggests that at least one group mean is different, leading to rejection of the null hypothesis. It‚Äôs commonly used in ANOVA and regression analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "i5mvX6ADstfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Practical Questions**"
      ],
      "metadata": {
        "id": "nGvlD-um4gwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and\n",
        "interpret the results.\n",
        "* from scipy.stats import norm\n",
        "import math\n",
        "\n",
        "# Sample data\n",
        "sample_mean = 105\n",
        "population_mean = 100\n",
        "population_std_dev = 15\n",
        "sample_size = 30\n",
        "alpha = 0.05  # significance level\n",
        "\n",
        "# Calculate the standard error\n",
        "standard_error = population_std_dev / math.sqrt(sample_size)\n",
        "\n",
        "# Calculate the Z-score\n",
        "z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "# Calculate the p-value for a two-tailed test\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Print results\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.3f}\")\n",
        "\n",
        "# Interpret the result\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The sample mean is significantly different from the population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between the sample mean and population mean.\")\n",
        "2. Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python.\n",
        "* import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate two random samples (group A and group B)\n",
        "group_a = np.random.normal(loc=50, scale=10, size=30)  # mean=50, std=10, n=30\n",
        "group_b = np.random.normal(loc=55, scale=10, size=30)  # mean=55, std=10, n=30\n",
        "\n",
        "# Perform independent two-sample t-test\n",
        "t_stat, p_value = ttest_ind(group_a, group_b)\n",
        "\n",
        "# Print t-statistic and p-value\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.3f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The group means are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: No significant difference between group means.\")\n",
        "3. Implement a one-sample Z-test using Python to compare the sample mean with the population mean.\n",
        "* from scipy.stats import norm\n",
        "import math\n",
        "\n",
        "# Given data\n",
        "sample_mean = 102\n",
        "population_mean = 100\n",
        "population_std_dev = 15\n",
        "sample_size = 40\n",
        "alpha = 0.05\n",
        "\n",
        "# Calculate standard error\n",
        "standard_error = population_std_dev / math.sqrt(sample_size)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "# Calculate two-tailed p-value\n",
        "p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
        "\n",
        "# Print results\n",
        "print(f\"Z-score: {z_score:.3f}\")\n",
        "print(f\"P-value: {p_value:.3f}\")\n",
        "\n",
        "# Decision\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Significant difference exists.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference.\")\n",
        "4. Perform a two-tailed Z-test using Python and visualize the decision region on a plot.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import math\n",
        "\n",
        "# Given data\n",
        "sample_mean = 108\n",
        "population_mean = 100\n",
        "population_std_dev = 12\n",
        "sample_size = 36\n",
        "alpha = 0.05\n",
        "\n",
        "# Calculate standard error\n",
        "standard_error = population_std_dev / math.sqrt(sample_size)\n",
        "\n",
        "# Calculate Z-score\n",
        "z_score = (sample_mean - population_mean) / standard_error\n",
        "\n",
        "# Critical Z-values for two-tailed test\n",
        "z_critical = norm.ppf(1 - alpha/2)\n",
        "\n",
        "# Create range for plotting\n",
        "x = np.linspace(-4, 4, 1000)\n",
        "y = norm.pdf(x)\n",
        "\n",
        "plt.plot(x, y, label='Standard Normal Distribution')\n",
        "\n",
        "# Shade rejection regions\n",
        "plt.fill_between(x, y, where=(x <= -z_critical), color='red', alpha=0.3, label='Rejection Region')\n",
        "plt.fill_between(x, y, where=(x >= z_critical), color='red', alpha=0.3)\n",
        "\n",
        "# Mark Z-score\n",
        "plt.axvline(z_score, color='blue', linestyle='--', label=f'Z-score = {z_score:.2f}')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.title('Two-tailed Z-test')\n",
        "plt.xlabel('Z-value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "5. Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "import math\n",
        "\n",
        "def plot_type1_type2(mu0, mu1, sigma, n, alpha):\n",
        "    # Calculate standard error\n",
        "    se = sigma / math.sqrt(n)\n",
        "\n",
        "    # Critical Z for two-tailed test\n",
        "    z_critical = norm.ppf(1 - alpha/2)\n",
        "\n",
        "    # Critical sample means (boundaries for rejection)\n",
        "    lower_crit = mu0 - z_critical * se\n",
        "    upper_crit = mu0 + z_critical * se\n",
        "\n",
        "    # X range covering both distributions\n",
        "    x_min = mu0 - 4 * se\n",
        "    x_max = mu1 + 4 * se\n",
        "    x = np.linspace(x_min, x_max, 1000)\n",
        "\n",
        "    # Null hypothesis distribution (H0)\n",
        "    null_dist = norm.pdf(x, mu0, se)\n",
        "    # Alternative hypothesis distribution (H1)\n",
        "    alt_dist = norm.pdf(x, mu1, se)\n",
        "\n",
        "    plt.plot(x, null_dist, label='H0: Œº = {:.2f}'.format(mu0))\n",
        "    plt.plot(x, alt_dist, label='H1: Œº = {:.2f}'.format(mu1))\n",
        "\n",
        "    # Shade Type 1 error regions (under null, outside critical values)\n",
        "    x_fill_left = np.linspace(x_min, lower_crit, 500)\n",
        "    plt.fill_between(x_fill_left, norm.pdf(x_fill_left, mu0, se), color='red', alpha=0.3, label='Type 1 Error (Œ±)')\n",
        "    x_fill_right = np.linspace(upper_crit, x_max, 500)\n",
        "    plt.fill_between(x_fill_right, norm.pdf(x_fill_right, mu0, se), color='red', alpha=0.3)\n",
        "\n",
        "    # Shade Type 2 error region (under alternative, between critical values)\n",
        "    x_fill_beta = np.linspace(lower_crit, upper_crit, 500)\n",
        "    plt.fill_between(x_fill_beta, norm.pdf(x_fill_beta, mu1, se), color='blue', alpha=0.3, label='Type 2 Error (Œ≤)')\n",
        "\n",
        "    # Labels and legend\n",
        "    plt.title('Type 1 and Type 2 Errors in Hypothesis Testing')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate beta (Type 2 error)\n",
        "    beta = norm.cdf(upper_crit, mu1, se) - norm.cdf(lower_crit, mu1, se)\n",
        "\n",
        "    print(f\"Type 1 error rate (Œ±): {alpha}\")\n",
        "    print(f\"Type 2 error rate (Œ≤): {beta:.4f}\")\n",
        "\n",
        "# Example usage:\n",
        "plot_type1_type2(mu0=100, mu1=105, sigma=15, n=36, alpha=0.05)\n",
        "6.  Write a Python program to perform an independent T-test and interpret the results.\n",
        "* import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Sample data: two independent groups\n",
        "group1 = np.array([23, 21, 19, 24, 30, 22, 20])\n",
        "group2 = np.array([31, 29, 35, 28, 34, 32, 30])\n",
        "\n",
        "# Perform independent t-test\n",
        "t_stat, p_value = ttest_ind(group1, group2)\n",
        "\n",
        "# Print results\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.3f}\")\n",
        "\n",
        "# Interpret results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Significant difference between group means.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between group means.\")\n",
        "7.  Perform a paired sample T-test using Python and visualize the comparison results.\n",
        "* import numpy as np\n",
        "from scipy.stats import ttest_rel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data: paired observations (e.g., before and after treatment)\n",
        "before = np.array([85, 78, 90, 88, 76, 95, 89])\n",
        "after = np.array([88, 80, 92, 90, 79, 96, 91])\n",
        "\n",
        "# Perform paired t-test\n",
        "t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "# Print results\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.3f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Significant difference between before and after.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between before and after.\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(len(before)), before, marker='o', label='Before')\n",
        "plt.plot(range(len(after)), after, marker='o', label='After')\n",
        "for i in range(len(before)):\n",
        "    plt.plot([i, i], [before[i], after[i]], color='gray', linestyle='--', alpha=0.7)\n",
        "plt.xticks(range(len(before)), [f'Subject {i+1}' for i in range(len(before))])\n",
        "plt.xlabel('Subjects')\n",
        "plt.ylabel('Measurement')\n",
        "plt.title('Paired Sample Comparison')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "8.  Simulate data and perform both Z-test and T-test, then compare the results using Python.\n",
        "* import numpy as np\n",
        "from scipy.stats import norm, t, ttest_1samp\n",
        "import math\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(123)\n",
        "\n",
        "# Population parameters\n",
        "population_mean = 100\n",
        "population_std_dev = 15\n",
        "\n",
        "# Simulate sample data\n",
        "sample_size = 40\n",
        "sample = np.random.normal(loc=102, scale=population_std_dev, size=sample_size)\n",
        "sample_mean = np.mean(sample)\n",
        "sample_std = np.std(sample, ddof=1)  # sample standard deviation\n",
        "\n",
        "# Z-test calculation (using population std dev)\n",
        "standard_error = population_std_dev / math.sqrt(sample_size)\n",
        "z_score = (sample_mean - population_mean) / standard_error\n",
        "p_value_z = 2 * (1 - norm.cdf(abs(z_score)))  # two-tailed\n",
        "\n",
        "# T-test calculation (using sample std dev)\n",
        "t_statistic, p_value_t = ttest_1samp(sample, population_mean)\n",
        "\n",
        "# Display results\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z-test: Z-score = {z_score:.3f}, P-value = {p_value_z:.3f}\")\n",
        "print(f\"T-test: T-statistic = {t_statistic:.3f}, P-value = {p_value_t:.3f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "print(\"\\nInterpretation:\")\n",
        "if p_value_z < alpha:\n",
        "    print(\"Z-test: Reject null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"Z-test: Fail to reject null hypothesis (no significant difference).\")\n",
        "\n",
        "if p_value_t < alpha:\n",
        "    print(\"T-test: Reject null hypothesis (significant difference).\")\n",
        "else:\n",
        "    print(\"T-test: Fail to reject null hypothesis (no significant difference).\")\n",
        "\n",
        "9. Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "* import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "def confidence_interval(sample, confidence=0.95):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "    sample (list or array): Sample data\n",
        "    confidence (float): Confidence level (default is 0.95 for 95%)\n",
        "\n",
        "    Returns:\n",
        "    tuple: Lower and upper bounds of the confidence interval\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    mean = sum(sample) / n\n",
        "    std_dev = (sum((x - mean) ** 2 for x in sample) / (n - 1)) ** 0.5\n",
        "    standard_error = std_dev / math.sqrt(n)\n",
        "\n",
        "    # Find the t critical value for the confidence level and degrees of freedom\n",
        "    t_critical = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    margin_of_error = t_critical * standard_error\n",
        "\n",
        "    lower_bound = mean - margin_of_error\n",
        "    upper_bound = mean + margin_of_error\n",
        "\n",
        "    return (lower_bound, upper_bound)\n",
        "\n",
        "# Example usage:\n",
        "sample_data = [12, 15, 14, 16, 13, 15, 14]\n",
        "ci_lower, ci_upper = confidence_interval(sample_data)\n",
        "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
        "10. Write a Python program to calculate the margin of error for a given confidence level using sample data.\n",
        "* import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "def margin_of_error(sample, confidence=0.95):\n",
        "    n = len(sample)\n",
        "    mean = sum(sample) / n\n",
        "    std_dev = (sum((x - mean) ** 2 for x in sample) / (n - 1)) ** 0.5\n",
        "    standard_error = std_dev / math.sqrt(n)\n",
        "\n",
        "    # Get the t critical value for the confidence level and degrees of freedom\n",
        "    t_critical = stats.t.ppf((1 + confidence) / 2, df=n-1)\n",
        "\n",
        "    margin = t_critical * standard_error\n",
        "    return margin\n",
        "\n",
        "# Example usage:\n",
        "sample_data = [10, 12, 11, 13, 12, 14, 11, 15]\n",
        "moe = margin_of_error(sample_data, confidence=0.95)\n",
        "print(f\"Margin of Error (95% confidence): {moe:.3f}\")\n",
        "11.  Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process.\n",
        "* def bayes_theorem(prior_disease, sensitivity, specificity):\n",
        "    # Prior probabilities\n",
        "    prior_no_disease = 1 - prior_disease\n",
        "\n",
        "    # Likelihoods\n",
        "    prob_pos_given_disease = sensitivity\n",
        "    prob_pos_given_no_disease = 1 - specificity\n",
        "\n",
        "    # Total probability of positive test\n",
        "    prob_positive = (prob_pos_given_disease * prior_disease) + (prob_pos_given_no_disease * prior_no_disease)\n",
        "\n",
        "    # Posterior probability: P(Disease | Positive test)\n",
        "    posterior = (prob_pos_given_disease * prior_disease) / prob_positive\n",
        "\n",
        "    return posterior\n",
        "\n",
        "# Example parameters\n",
        "prior_disease = 0.01       # 1% prevalence\n",
        "sensitivity = 0.95         # 95% true positive rate\n",
        "specificity = 0.90         # 90% true negative rate\n",
        "\n",
        "posterior_probability = bayes_theorem(prior_disease, sensitivity, specificity)\n",
        "print(f\"Probability of having the disease given a positive test: {posterior_probability:.4f}\")\n",
        "12. Perform a Chi-square test for independence between two categorical variables in Python.\n",
        "* import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Example contingency table:\n",
        "# Rows = Category A levels, Columns = Category B levels\n",
        "# For example: Gender (Male/Female) vs Preference (Yes/No)\n",
        "contingency_table = np.array([[30, 10],\n",
        "                              [20, 40]])\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.3f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(\"Expected frequencies:\")\n",
        "print(expected)\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis: variables are dependent (associated).\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: variables are independent.\")\n",
        "13. Write a Python program to calculate the expected frequencies for a Chi-square test based on observed\n",
        "data.\n",
        "* import numpy as np\n",
        "\n",
        "def calculate_expected_frequencies(observed):\n",
        "    # Convert to numpy array if not already\n",
        "    observed = np.array(observed)\n",
        "\n",
        "    # Calculate row sums and column sums\n",
        "    row_sums = observed.sum(axis=1).reshape(-1, 1)  # column vector\n",
        "    col_sums = observed.sum(axis=0).reshape(1, -1)  # row vector\n",
        "\n",
        "    # Total sum of all observations\n",
        "    total = observed.sum()\n",
        "\n",
        "    # Calculate expected frequencies matrix\n",
        "    expected = (row_sums @ col_sums) / total\n",
        "\n",
        "    return expected\n",
        "\n",
        "# Example observed contingency table\n",
        "observed_data = [\n",
        "    [30, 10],\n",
        "    [20, 40]\n",
        "]\n",
        "\n",
        "expected_freq = calculate_expected_frequencies(observed_data)\n",
        "print(\"Expected Frequencies:\")\n",
        "print(expected_freq)\n",
        "14. Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution.\n",
        "* import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed counts (e.g., counts of categories in your data)\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "# Expected proportions (e.g., theoretical probabilities for each category)\n",
        "expected_probs = np.array([0.4, 0.4, 0.2])\n",
        "\n",
        "# Convert expected proportions to expected counts\n",
        "expected_counts = expected_probs * observed.sum()\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected_counts)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: observed data does NOT fit expected distribution.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: observed data fits expected distribution.\")\n",
        "15. Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristics.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Parameters\n",
        "degrees_of_freedom = [1, 2, 5, 10, 20]\n",
        "x = np.linspace(0, 40, 500)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot Chi-square PDFs for different degrees of freedom\n",
        "for df in degrees_of_freedom:\n",
        "    y = chi2.pdf(x, df)\n",
        "    plt.plot(x, y, label=f'df = {df}')\n",
        "\n",
        "plt.title('Chi-square Distribution for Different Degrees of Freedom')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "16. Implement an F-test using Python to compare the variances of two random samples.\n",
        "* import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "# Generate two random samples\n",
        "np.random.seed(42)\n",
        "sample1 = np.random.normal(loc=50, scale=5, size=30)  # mean=50, std=5\n",
        "sample2 = np.random.normal(loc=50, scale=8, size=35)  # mean=50, std=8\n",
        "\n",
        "# Calculate sample variances\n",
        "var1 = np.var(sample1, ddof=1)\n",
        "var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "# Calculate F-statistic (ratio of larger variance to smaller variance)\n",
        "if var1 > var2:\n",
        "    f_stat = var1 / var2\n",
        "    dfn = len(sample1) - 1  # degrees of freedom numerator\n",
        "    dfd = len(sample2) - 1  # degrees of freedom denominator\n",
        "else:\n",
        "    f_stat = var2 / var1\n",
        "    dfn = len(sample2) - 1\n",
        "    dfd = len(sample1) - 1\n",
        "\n",
        "# Calculate the p-value for two-tailed test\n",
        "p_value = 2 * min(f.cdf(f_stat, dfn, dfd), 1 - f.cdf(f_stat, dfn, dfd))\n",
        "\n",
        "print(f\"Sample Variance 1: {var1:.3f}\")\n",
        "print(f\"Sample Variance 2: {var2:.3f}\")\n",
        "print(f\"F-statistic: {f_stat:.3f}\")\n",
        "print(f\"Degrees of freedom: numerator={dfn}, denominator={dfd}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference in variances.\")\n",
        "17. Write a Python program to perform an ANOVA test to compare means between multiple groups and\n",
        "interpret the results.\n",
        "* import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Sample data: three groups with different values\n",
        "group1 = np.array([23, 20, 22, 21, 24])\n",
        "group2 = np.array([30, 29, 31, 28, 32])\n",
        "group3 = np.array([25, 27, 26, 24, 23])\n",
        "\n",
        "# Perform one-way ANOVA test\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"F-statistic: {f_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between group means.\")\n",
        "18. Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Sample data: three groups\n",
        "group1 = np.array([23, 20, 22, 21, 24])\n",
        "group2 = np.array([30, 29, 31, 28, 32])\n",
        "group3 = np.array([25, 27, 26, 24, 23])\n",
        "\n",
        "groups = [group1, group2, group3]\n",
        "group_labels = ['Group 1', 'Group 2', 'Group 3']\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(*groups)\n",
        "print(f\"F-statistic: {f_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between group means.\")\n",
        "\n",
        "# Plot means with error bars (standard deviation)\n",
        "means = [np.mean(g) for g in groups]\n",
        "std_devs = [np.std(g, ddof=1) for g in groups]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(group_labels, means, yerr=std_devs, capsize=10, color='skyblue', edgecolor='black')\n",
        "plt.ylabel('Mean Value')\n",
        "plt.title('Group Means with Standard Deviation Error Bars')\n",
        "plt.show()\n",
        "19. Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA.\n",
        "* import numpy as np\n",
        "from scipy.stats import shapiro, levene\n",
        "\n",
        "def check_anova_assumptions(groups):\n",
        "    \"\"\"\n",
        "    Checks ANOVA assumptions:\n",
        "    1. Normality of each group (Shapiro-Wilk test)\n",
        "    2. Equal variances across groups (Levene's test)\n",
        "    3. Independence is assumed by study design (no test here)\n",
        "\n",
        "    Args:\n",
        "    groups: list of arrays or lists, each representing one group\n",
        "\n",
        "    Returns:\n",
        "    Dictionary summarizing test results\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # 1. Normality test for each group\n",
        "    normality_results = []\n",
        "    for i, group in enumerate(groups, 1):\n",
        "        stat, p = shapiro(group)\n",
        "        normality_results.append((stat, p))\n",
        "    results['normality'] = normality_results\n",
        "\n",
        "    # 2. Equal variances across groups\n",
        "    stat_levene, p_levene = levene(*groups)\n",
        "    results['equal_variances'] = (stat_levene, p_levene)\n",
        "\n",
        "    # 3. Independence - no direct test; must be checked by experimental design\n",
        "    results['independence'] = \"Assumed based on study design; no statistical test\"\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "group1 = [23, 20, 22, 21, 24]\n",
        "group2 = [30, 29, 31, 28, 32]\n",
        "group3 = [25, 27, 26, 24, 23]\n",
        "\n",
        "assumption_results = check_anova_assumptions([group1, group2, group3])\n",
        "\n",
        "for i, (stat, p) in enumerate(assumption_results['normality'], 1):\n",
        "    print(f\"Group {i} Normality (Shapiro-Wilk): stat={stat:.3f}, p={p:.4f}\")\n",
        "\n",
        "stat_levene, p_levene = assumption_results['equal_variances']\n",
        "print(f\"Levene's Test for Equal Variances: stat={stat_levene:.3f}, p={p_levene:.4f}\")\n",
        "\n",
        "print(f\"Independence: {assumption_results['independence']}\")\n",
        "20. Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the\n",
        "results.\n",
        "* import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create example dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Factors: Factor A (2 levels), Factor B (3 levels)\n",
        "factor_A = np.repeat(['A1', 'A2'], 15)\n",
        "factor_B = np.tile(np.repeat(['B1', 'B2', 'B3'], 5), 2)\n",
        "\n",
        "# Response variable with some interaction effect + noise\n",
        "response = (np.array([5, 7, 9, 6, 8, 10, 7, 9, 11, 6, 8, 10, 7, 9, 11,\n",
        "                      6, 8, 10, 5, 7, 9, 6, 8, 10, 5, 7, 9, 6, 8, 10]) +\n",
        "            np.random.normal(0, 1, 30))\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({'FactorA': factor_A, 'FactorB': factor_B, 'Response': response})\n",
        "\n",
        "# Fit two-way ANOVA model with interaction\n",
        "model = ols('Response ~ C(FactorA) * C(FactorB)', data=df).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(\"Two-way ANOVA results:\")\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization: Interaction plot using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.pointplot(x='FactorB', y='Response', hue='FactorA', data=df,\n",
        "              dodge=True, markers=['o', 's'], capsize=0.1, errwidth=1, palette='Set2')\n",
        "plt.title('Interaction Plot: FactorA and FactorB')\n",
        "plt.ylabel('Mean Response')\n",
        "plt.show()\n",
        "21.  Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Define degrees of freedom for numerator and denominator\n",
        "dfn = 5   # degrees of freedom numerator\n",
        "dfd = 10  # degrees of freedom denominator\n",
        "\n",
        "# Generate x values\n",
        "x = np.linspace(0, 5, 500)\n",
        "\n",
        "# Compute the F-distribution PDF\n",
        "y = f.pdf(x, dfn, dfd)\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(x, y, label=f'F-distribution (dfn={dfn}, dfd={dfd})', color='blue')\n",
        "plt.fill_between(x, y, alpha=0.3, color='skyblue')\n",
        "plt.title('F-distribution (Probability Density Function)')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "22. Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import f_oneway\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data for three groups\n",
        "group1 = [22, 20, 21, 19, 23]\n",
        "group2 = [28, 30, 27, 29, 31]\n",
        "group3 = [24, 23, 25, 22, 26]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(f\"F-statistic: {f_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between group means.\")\n",
        "\n",
        "# Combine data into a single DataFrame for visualization\n",
        "data = group1 + group2 + group3\n",
        "labels = ['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3)\n",
        "df = pd.DataFrame({'Group': labels, 'Values': data})\n",
        "\n",
        "# Plot boxplots\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='Group', y='Values', data=df, palette='Set3')\n",
        "plt.title('Boxplot Comparison of Group Means')\n",
        "plt.ylabel('Values')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "23. Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means.\n",
        "* import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Simulate random data from a normal distribution\n",
        "np.random.seed(42)\n",
        "sample_size = 50\n",
        "population_mean = 100\n",
        "sample_data = np.random.normal(loc=102, scale=10, size=sample_size)  # Simulated sample\n",
        "\n",
        "# Step 2: Perform one-sample t-test\n",
        "t_stat, p_value = ttest_1samp(sample_data, popmean=population_mean)\n",
        "\n",
        "print(f\"Sample Mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"T-statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 3: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference from population mean.\")\n",
        "\n",
        "# Step 4: Plot histogram of sample data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(sample_data, bins=10, color='skyblue', edgecolor='black')\n",
        "plt.axvline(np.mean(sample_data), color='red', linestyle='--', label='Sample Mean')\n",
        "plt.axvline(population_mean, color='green', linestyle='-', label='Population Mean')\n",
        "plt.title('Simulated Sample Data from Normal Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "24. Perform a hypothesis test for population variance using a Chi-square distribution and interpret the results.\n",
        "* import numpy as np\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Sample data\n",
        "data = [12, 15, 14, 10, 13, 15, 14, 13, 11, 12]\n",
        "sample_size = len(data)\n",
        "sample_variance = np.var(data, ddof=1)\n",
        "hypothesized_variance = 4  # H0: population variance = 4\n",
        "\n",
        "# Chi-square statistic\n",
        "chi_square_stat = (sample_size - 1) * sample_variance / hypothesized_variance\n",
        "\n",
        "# Degrees of freedom\n",
        "df = sample_size - 1\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Critical values for two-tailed test\n",
        "chi2_lower = chi2.ppf(alpha / 2, df)\n",
        "chi2_upper = chi2.ppf(1 - alpha / 2, df)\n",
        "\n",
        "# Print results\n",
        "print(f\"Sample Variance: {sample_variance:.2f}\")\n",
        "print(f\"Chi-square Statistic: {chi_square_stat:.3f}\")\n",
        "print(f\"Chi-square Critical Values: Lower = {chi2_lower:.3f}, Upper = {chi2_upper:.3f}\")\n",
        "\n",
        "# Decision\n",
        "if chi_square_stat < chi2_lower or chi_square_stat > chi2_upper:\n",
        "    print(\"Reject null hypothesis: Population variance is significantly different from hypothesized variance.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference from hypothesized population variance.\")\n",
        "25. Write a Python script to perform a Z-test for comparing proportions between two datasets or groups.\n",
        "* import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Sample data: successes and sample sizes for two groups\n",
        "successes = np.array([45, 30])\n",
        "samples = np.array([100, 80])\n",
        "\n",
        "# Perform two-proportion Z-test\n",
        "z_stat, p_value = proportions_ztest(successes, samples)\n",
        "\n",
        "print(f\"Z-statistic: {z_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: The proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between proportions.\")\n",
        "26. Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results.\n",
        "* import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Sample data\n",
        "data1 = np.array([12, 15, 14, 10, 13, 15, 14, 13, 11, 12])\n",
        "data2 = np.array([22, 25, 19, 23, 21, 24, 20, 22, 23, 21])\n",
        "\n",
        "# Calculate sample variances and sizes\n",
        "var1 = np.var(data1, ddof=1)\n",
        "var2 = np.var(data2, ddof=1)\n",
        "n1 = len(data1)\n",
        "n2 = len(data2)\n",
        "\n",
        "# Calculate F-statistic (larger variance / smaller variance)\n",
        "if var1 > var2:\n",
        "    F = var1 / var2\n",
        "    dfn, dfd = n1 - 1, n2 - 1\n",
        "else:\n",
        "    F = var2 / var1\n",
        "    dfn, dfd = n2 - 1, n1 - 1\n",
        "\n",
        "# Calculate p-value for two-tailed test\n",
        "p_value = 2 * min(f.cdf(F, dfn, dfd), 1 - f.cdf(F, dfn, dfd))\n",
        "\n",
        "print(f\"Variance 1: {var1:.2f}, Variance 2: {var2:.2f}\")\n",
        "print(f\"F-statistic: {F:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject null hypothesis: Variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference between variances.\")\n",
        "\n",
        "# Visualization of F-distribution and observed F-statistic\n",
        "x = np.linspace(0, 5, 500)\n",
        "y = f.pdf(x, dfn, dfd)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(x, y, label=f'F-distribution (dfn={dfn}, dfd={dfd})')\n",
        "plt.axvline(F, color='red', linestyle='--', label=f'Observed F = {F:.2f}')\n",
        "plt.fill_between(x, 0, y, alpha=0.3)\n",
        "plt.title('F-distribution with Observed F-statistic')\n",
        "plt.xlabel('F-value')\n",
        "plt.ylabel('Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "27. Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
        "* import numpy as np\n",
        "from scipy.stats import chi2_contingency, chisquare\n",
        "\n",
        "# Simulated observed frequencies (e.g., counts in categories)\n",
        "observed = np.array([50, 30, 20])\n",
        "\n",
        "# Expected frequencies under the null hypothesis (equal distribution)\n",
        "expected = np.array([33.33, 33.33, 33.33])\n",
        "\n",
        "# Perform Chi-square goodness of fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square Statistic: {chi2_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: Observed frequencies differ significantly from expected.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: No significant difference from expected frequencies.\")\n"
      ],
      "metadata": {
        "id": "XB0OqnW64lK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}